{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"CNNC_patcher3000.ipynb","provenance":[{"file_id":"1v4w2Zu7Prn3-fXItceraTVuzlhxbWrhI","timestamp":1576237095356}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"e1LOZWNFB-iY","colab_type":"code","outputId":"93156064-a965-4996-9e36-e18799f3a699","executionInfo":{"status":"ok","timestamp":1576261304470,"user_tz":-60,"elapsed":20965,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r4wy9Ac1CHc0","colab_type":"code","outputId":"932cb2a4-6b34-427d-d63d-78846c501148","executionInfo":{"status":"ok","timestamp":1576261309846,"user_tz":-60,"elapsed":1340,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd drive/'My Drive'/'Colab Notebooks'/Road_seg"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Road_seg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"OnjZT0PsB5bo","colab_type":"code","outputId":"0bc33f99-ae18-443c-97d3-a7556c4d6cdd","executionInfo":{"status":"ok","timestamp":1576261314590,"user_tz":-60,"elapsed":6070,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","import os,sys\n","import albumentations as albu\n","from PIL import Image\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"E5kLYc9yB5br","colab_type":"text"},"source":["# Loading the dataset"]},{"cell_type":"code","metadata":{"id":"Ot8dMTi_B5bs","colab_type":"code","colab":{}},"source":["import helperC"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVz22Be6DdVR","colab_type":"code","colab":{}},"source":["def patcher_3000(img, cp_size, p_size):\n","    list_patches = []\n","    padding = int((p_size - cp_size) / 2)\n","    padded_img = np.pad(img, ((padding, padding),(padding, padding), (0,0)), mode='symmetric')\n","\n","    imgwidth = img.shape[0]\n","    imgheight = img.shape[1]\n","\n","    for i in range(0, imgheight, cp_size):\n","        for j in range(0, imgwidth, cp_size):\n","            im_patch = padded_img[j:j+cp_size+2*padding, i:i+cp_size+2*padding, :]\n","            list_patches.append(im_patch)\n","            \n","    \n","    return list_patches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZhYu2xdB5bu","colab_type":"code","outputId":"fff5fb37-383e-4853-8257-9975b5d1dda4","executionInfo":{"status":"ok","timestamp":1576261385253,"user_tz":-60,"elapsed":76706,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Loaded a set of images\n","root_dir = \"Datasets/training/\"\n","\n","n = 100\n","\n","image_dir = root_dir + \"images/\"\n","files = os.listdir(image_dir)\n","print(\"Loading \" + str(n) + \" images\")\n","imgs = [helperC.load_image(image_dir + files[i]) for i in range(n)]\n","\n","gt_dir = root_dir + \"groundtruth/\"\n","print(\"Loading \" + str(n) + \" images\")\n","gt_imgs = [helperC.load_image(gt_dir + files[i]) for i in range(n)]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loading 100 images\n","Loading 100 images\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zeRItWMLB5bw","colab_type":"text"},"source":["#### Data Augmentation\n","##### From https://towardsdatascience.com/road-detection-using-segmentation-models-and-albumentations-libraries-on-keras-d5434eaf73a8\n"]},{"cell_type":"code","metadata":{"id":"d1pdpsjhB5bx","colab_type":"code","colab":{}},"source":["#Doubles the nb of images. Needs improvement\n","#for i in range(2):\n","  for n in range(len(gt_imgs)):\n","    augmented = helperC.image_augmentation(image_size = 256)(image=imgs[n], mask=gt_imgs[n])\n","    imgs.append(augmented['image'])\n","    gt_imgs.append(augmented['mask'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ub9-4peCB5bz","colab_type":"code","colab":{}},"source":["# Extract patches from input images\n","patch_size = 16 # each patch is 16*16 pixels\n","window_size=100\n","img_patches = [patcher_3000(imgs[i], patch_size, window_size) for i in range(len(imgs))]\n","gt_patches = [helperC.img_crop(gt_imgs[i], patch_size, patch_size) for i in range(len(gt_imgs))]\n","\n","# Linearize list of patches\n","img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n","gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n","gt_patches = helperC.patches_labelization(gt_patches)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2N4UibwXTd8_","colab_type":"code","outputId":"780ce649-4492-461b-c522-5c9288266c7e","executionInfo":{"status":"ok","timestamp":1576261390938,"user_tz":-60,"elapsed":82335,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(img_patches.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(125000, 100, 100, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KmhEKpT4B5b0","colab_type":"text"},"source":["## Feature processing "]},{"cell_type":"markdown","metadata":{"id":"WxwmZIZzB5b1","colab_type":"text"},"source":["#### Balancing amount of patches  background vs road for training"]},{"cell_type":"code","metadata":{"id":"YR69LdrXB5b1","colab_type":"code","colab":{}},"source":["\n","#img_patches, gt_patches = helper.feature_balancing(img_patches, gt_patches)\n","#Works badly!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k1T67phnB5b3","colab_type":"text"},"source":["# CNN"]},{"cell_type":"code","metadata":{"id":"0H9_-Bl0B5b4","colab_type":"code","colab":{}},"source":["from tensorflow.keras import datasets, layers, models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7avgio7tB5b5","colab_type":"text"},"source":["## Layers"]},{"cell_type":"code","metadata":{"id":"eyf0nqDjB5b6","colab_type":"code","outputId":"3885c8a1-2b94-4835-9720-2196fffa496e","executionInfo":{"status":"ok","timestamp":1576261391275,"user_tz":-60,"elapsed":82647,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["from keras.regularizers import l2\n","\"\"\"model = models.Sequential()\n","reg = 1e-6 # L2 regularization factor (used on weights, but not biases)\n","### heavily(!) inspired from a previous project. Needs to be changed/optimized\n","model.add(layers.Convolution2D(64, 5, 5, padding='same',input_shape=(16, 16, 3)))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Convolution2D(128, 3, 3,padding='same'))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Convolution2D(256, 3, 3, padding='same'))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Convolution2D(256, 3, 3, padding='same'))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, kernel_regularizer=l2(reg))) # Fully connected layer (128 neurons)\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(2, kernel_regularizer=l2(reg)))\n","\"\"\"\n","\n","\"\"\"model = models.Sequential()\n","\n","model.add(layers.Conv2D(32, (2, 2), input_shape=(16, 16, 3)))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (2, 2)))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.Conv2D(128, (2, 2)))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64))\n","model.add(layers.LeakyReLU(alpha=0.1))\n","model.add(layers.Dense(2, activation='softmax'))\"\"\"\n","model = models.Sequential()\n","lrelu = lambda x: tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n","kernel_size3 = (3,3)\n","kernel_size2 = (2,2)\n","pool_size = (2,2)\n","alpha_relu = 0.1\n","regularizer = 1e-6\n","shape = (window_size, window_size, 3)\n","\n","model.add(layers.Convolution2D(64,kernel_size2,activation = lrelu, input_shape=shape))\n","model.add(layers.MaxPooling2D(pool_size))\n","model.add(layers.Convolution2D(64, kernel_size2,activation = lrelu))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.MaxPooling2D(pool_size))\n","\n","model.add(layers.Convolution2D(128, kernel_size2,activation = lrelu))\n","model.add(layers.MaxPooling2D(pool_size))\n","model.add(layers.Convolution2D(128,kernel_size2,activation = lrelu))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.MaxPooling2D(pool_size))\n","\n","model.add(layers.Convolution2D(256,kernel_size2,activation = lrelu))\n","model.add(layers.MaxPooling2D(pool_size))\n","model.add(layers.Convolution2D(256,kernel_size2,activation = lrelu))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(2, activation='softmax'))\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jvU5rMaBB5b8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"outputId":"acbac3b6-bd95-43e0-c94c-5ede2c9621d4","executionInfo":{"status":"ok","timestamp":1576261391276,"user_tz":-60,"elapsed":82639,"user":{"displayName":"Cindy Leyvraz","photoUrl":"","userId":"12018256886595068577"}}},"source":["model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 99, 99, 64)        832       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 48, 48, 64)        16448     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 23, 23, 128)       32896     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 10, 10, 128)       65664     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 4, 4, 256)         131328    \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 1, 1, 256)         262400    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 256)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 514       \n","=================================================================\n","Total params: 510,082\n","Trainable params: 510,082\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"invAaRVmB5b-","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"qvO3ocxrB5b_","colab_type":"code","colab":{}},"source":["\n","def generate_minibatch(X, Y, batch_size):\n","    \"\"\"\n","    Procedure for real-time minibatch creation and image augmentation.\n","     This runs in a parallel thread while the model is being trained.\n","    \"\"\"\n","    Y = tf.keras.utils.to_categorical(Y, 2)\n","    while 1:\n","        # Generate one minibatch\n","        X_batch = np.empty((batch_size, window_size,window_size, 3))\n","        Y_batch = np.empty((batch_size, 2))\n","        for i in range(batch_size):\n","            # Select a random image\n","            idx = np.random.choice(X.shape[0])\n","                      \n","            # The label does not depend on the image rotation/flip (provided that the rotation is in steps of 90°)\n","            X_batch[i] = X[idx]\n","            Y_batch[i] = Y[idx]\n","        yield (X_batch, Y_batch)\n","          "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"h61yTay3B5cA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":799},"outputId":"bd05af73-0512-444d-e7d6-20bb9e79e1d7"},"source":["import math\n","\n","batch_size = 64\n","steps_per_epoch = math.ceil(img_patches.shape[0] / batch_size)\n","\"\"\"def softmax_categorical_crossentropy(y_true, y_pred):\n","       \n","        Uses categorical cross-entropy from logits in order to improve numerical stability.\n","        This is especially useful for TensorFlow (less useful for Theano).           \n","        return K.categorical_crossentropy(y_pred, y_true, from_logits=True)\n","    \"\"\"\n","model.compile(loss = \"categorical_crossentropy\",  optimizer = keras.optimizers.Adam(lr=1e-3),\n","              metrics = ['accuracy'])\n","#Y = tf.keras.utils.to_categorical(gt_patches, 2)\n","\n","        \n","#model.fit(img_patches, Y, batch_size = 64, epochs = 5, validation_split = 0.2)\n","model.fit_generator(generate_minibatch(img_patches,gt_patches, batch_size),\n","                    epochs=25, steps_per_epoch= steps_per_epoch)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","1954/1954 [==============================] - 56s 29ms/step - loss: 0.3138 - acc: 0.8560\n","Epoch 2/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.1426 - acc: 0.9435\n","Epoch 3/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0972 - acc: 0.9628\n","Epoch 4/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0727 - acc: 0.9727\n","Epoch 5/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0589 - acc: 0.9785\n","Epoch 6/25\n","1954/1954 [==============================] - 53s 27ms/step - loss: 0.0505 - acc: 0.9820\n","Epoch 7/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0438 - acc: 0.9843\n","Epoch 8/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0410 - acc: 0.9855\n","Epoch 9/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0370 - acc: 0.9869\n","Epoch 10/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0337 - acc: 0.9884\n","Epoch 11/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0319 - acc: 0.9886\n","Epoch 12/25\n","1954/1954 [==============================] - 53s 27ms/step - loss: 0.0305 - acc: 0.9895\n","Epoch 13/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0296 - acc: 0.9898\n","Epoch 14/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0290 - acc: 0.9902\n","Epoch 15/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0257 - acc: 0.9912\n","Epoch 16/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0272 - acc: 0.9911\n","Epoch 17/25\n","1954/1954 [==============================] - 53s 27ms/step - loss: 0.0246 - acc: 0.9917\n","Epoch 18/25\n","1954/1954 [==============================] - 53s 27ms/step - loss: 0.0257 - acc: 0.9913\n","Epoch 19/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0237 - acc: 0.9920\n","Epoch 20/25\n","1954/1954 [==============================] - 53s 27ms/step - loss: 0.0228 - acc: 0.9923\n","Epoch 21/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0233 - acc: 0.9927\n","Epoch 22/25\n","1954/1954 [==============================] - 52s 27ms/step - loss: 0.0220 - acc: 0.9927\n","Epoch 23/25\n","1405/1954 [====================>.........] - ETA: 14s - loss: 0.0225 - acc: 0.9925"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CUMZ9jyxUGBx","colab_type":"code","colab":{}},"source":["weights = model.get_weights()  # Retrieves the state of the model.\n","#model.set_weights(weights)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8gyqCvGB5cC","colab_type":"text"},"source":["## Predictions"]},{"cell_type":"code","metadata":{"id":"2dSKKOwwB5cD","colab_type":"code","colab":{}},"source":["#predictions = model.predict(img_patches)\n","#predictions = (predictions[:,0] < predictions[:,1]) * 1\n","#predictions = np.squeeze(predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eu490HUEB5cE","colab_type":"code","colab":{}},"source":["#predictions = np.squeeze(helper.binarize_predictions(predictions))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhqIafQxB5cG","colab_type":"code","colab":{}},"source":["#np.set_printoptions(threshold=sys.maxsize)\n","#print(predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NclkNHCrB5cI","colab_type":"text"},"source":["# Displaying predictions"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"tjqpesgYB5cI","colab_type":"code","colab":{}},"source":["\"\"\"# Display prediction as an image\n","img_idx = 2\n","\n","img_indexed = imgs[img_idx]\n","img_pat = helper.img_crop(img_indexed, patch_size, patch_size)\n","img_pat = np.asarray(img_pat)\n","prediction = model.predict(img_pat)\n","\n","w = gt_imgs[img_idx].shape[0]\n","h = gt_imgs[img_idx].shape[1]\n","predicted_im = helper.label_to_img_array(w, h, patch_size, patch_size, helper.binarize_predictions(prediction))\n","cimg = helper.concatenate_images(imgs[img_idx], predicted_im)\n","fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n","plt.imshow(cimg, cmap='Greys_r')\n","\n","new_img = helper.make_img_overlay(imgs[img_idx], predicted_im)\n","\n","#plt.imshow(new_img)\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bb6VhHHEB5cK","colab_type":"text"},"source":["# Create Submission"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SpwYMdMsB5cK","colab_type":"code","colab":{}},"source":["import submission as sub"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"xWYtgEpQB5cM","colab_type":"code","colab":{}},"source":["n = 50\n","patch_size = 16 \n","\n","img_test = []\n","\n","for i in range(1, 51):\n","    image_filename = 'Datasets/test_set_images/test_' + str(i) + '/test_' + str(i) + '.png' \n","    img_test.append(helperC.load_image(image_filename))\n","img_patches_test = [patcher_3000(img_test[i], patch_size, window_size) for i in range(n)]\n","img_patches_test = np.asarray([img_patches_test[i][j] for i in range(len(img_patches_test))\n","                               for j in range(len(img_patches_test[i]))])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"gzc9VHcmB5cN","colab_type":"code","colab":{}},"source":["predictions = model.predict(img_patches_test)\n","#predictions = np.squeeze(helper.binarize_predictions(predictions))\n","print(predictions.shape)\n","#print(predictions[10])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wafVyLKiB5cR","colab_type":"code","colab":{}},"source":["\n","\n","\"\"\"np.set_printoptions(threshold=sys.maxsize)\n","print(predictions.shape)\n","print(predictions)\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnl-WrY_B5cT","colab_type":"text"},"source":["### Post-processing"]},{"cell_type":"code","metadata":{"id":"Y_lGVYBceIwe","colab_type":"code","colab":{}},"source":["import cv2\n","def morphological(img):\n","    kernel = np.ones((17,17),np.uint8)\n","    op = cv2.morphologyEx(img,cv2.MORPH_OPEN, kernel)\n","    cl = cv2.morphologyEx(op,cv2.MORPH_CLOSE,kernel)   \n","    return cl"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7ET4ZnYB5cU","colab_type":"code","colab":{}},"source":["\n","prediction_patches =[]\n","#predictions = np.squeeze(helper.binarize_predictions(predictions))\n","predictions = (predictions[:,0] < predictions[:,1]) * 1\n","predictions = np.squeeze(predictions)\n","for i in range(50):\n","    #predictions = np.squeeze(helper.binarize_predictions(predictions))\n","    #prediction = helper.binarize_predictions_array(predictions[i*1444 :((i*1444)+1444)])\n","    prediction = helperC.label_to_img_patches_test(predictions[i*1444 :((i*1444)+1444)])\n","    #prediction = helperC.combine_surounded_patches(prediction) #Which order? Is it even useful. \n","    #prediction = helperC.remove_lonely_patches(prediction)\n","    prediciton = morphological(prediction)\n","    #prediction = morphological(prediction)\n","    prediction_patches.append(prediction) \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"MFKfLS9DB5cV","colab_type":"code","colab":{}},"source":["\n","img_patches_test_mod = [helperC.img_crop(prediction_patches[i], 1, 1)\n","                        for i in range(len(prediction_patches))]\n","\n","img_patches_test_mod =  np.asarray([img_patches_test_mod[i][j] for i in range(len(img_patches_test_mod))\n","                                     for j in range(len(img_patches_test_mod[i]))])\n","\n","\"\"\"img_patches_test_mod = np.asarray([prediction_patches[i][j] for i in range(len(prediction_patches)) \n","                               for j in range(len(prediction_patches[i]))])\"\"\"\n","\n","predictions_mod = np.squeeze(img_patches_test_mod)\n","\n","sub.create_pred_images(predictions_mod)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"vEjo1kC2B5cX","colab_type":"code","colab":{}},"source":["submission_filename = 'submission3.csv'\n","   \n","sub.create_submission(submission_filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDqj8EmOB5ce","colab_type":"code","colab":{}},"source":["#Just to have a look..\n","print(img_patches_test_mod.shape)\n","print(img_patches_test.shape)\n","for i in range(25):\n","    fig1 = plt.figure(figsize=(5, 5))\n","    plt.imshow(prediction_patches[i], cmap='Greys_r')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKWs0qqUB5cf","colab_type":"code","colab":{}},"source":["for i in range(25):\n","    fig1 = plt.figure(figsize=(5, 5))\n","    plt.imshow(img_test[i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLo0LBhfB5cg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOaB-kcbB5ci","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xsnRX-DB5cj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}