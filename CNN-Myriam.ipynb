{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import helper\n",
    "import pandas as pd \n",
    "import h5py\n",
    "import keras\n",
    "from keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 images\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"Datasets/training/\"\n",
    "\n",
    "n = 100\n",
    "\n",
    "imgs = []\n",
    "gt_imgs = []\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [helper.load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [helper.load_image(gt_dir + files[i]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize \n",
    "#standardize(imgs)\n",
    "\n",
    "#convert all imgs to uint8 type \n",
    "uint8_imgs = [None] * len(imgs)\n",
    "for i, image in enumerate(imgs): \n",
    "    uint8_img = helper.img_float_to_uint8(image)\n",
    "    uint8_imgs[i] = uint8_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Types of augmentation\"\n",
    "random.seed(42)\n",
    "\n",
    "light = albu.Compose([albu.RandomBrightnessContrast(p=1),albu.RandomGamma(p=1), albu.CLAHE(p=1)], p=1)\n",
    "\n",
    "medium = albu.Compose([albu.CLAHE(p=1), albu.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=50, val_shift_limit=50, p=1)], p=1)\n",
    "\n",
    "strong = albu.Compose([albu.ChannelShuffle(p=1)], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_imgs(aug, original_set,ground_set, plot = False): \n",
    "    \n",
    "    new =[None] * len(original_set)\n",
    "    gt = [None] * len(ground_set)\n",
    "    \n",
    "    final = original_set.copy()\n",
    "    gt_final = ground_set.copy()\n",
    "    for i, image in enumerate(original_set):\n",
    "        new[i] = augment_and_show(aug, image, show = plot)\n",
    "        gt[i] = ground_set[i]\n",
    "    \n",
    "    final.extend(new)\n",
    "    gt_final.extend(gt)\n",
    "\n",
    "    return final, gt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(sat, bk, patch_size = 16):\n",
    "    \n",
    "    img_patches = [helper.img_crop(sat[i], patch_size, patch_size) for i in range(len(sat))]\n",
    "    gt_patches = [helper.img_crop(bk[i], patch_size, patch_size) for i in range(len(bk))]\n",
    "    \n",
    "    # Linearize list of patches\n",
    "    img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "    gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    gt_patches = helper.patches_labelization(gt_patches)\n",
    "\n",
    "    return img_patches, gt_patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid shuffle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patches, gt_patches = extract_patches(imgs, gt_imgs)\n",
    "y = to_categorical(gt_patches) #for categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light augmentation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgslight, augmented_gt = augment_imgs(light, uint8_imgs, gt_imgs)\n",
    "augmentedlight_patches, augmentedlightgt_patches = extract_patches(augmented_imgslight, augmented_gt)\n",
    "ylight = to_categorical(augmentedlightgt_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgsmedium, augmented_gt = augment_imgs(medium, uint8_imgs, gt_imgs)\n",
    "augmentedmedium_patches, augmentedmediumgt_patches = extract_patches(augmented_imgsmedium, augmented_gt)\n",
    "ymedium = to_categorical(augmentedmediumgt_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strong augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgsstrong, augmented_gt = augment_imgs(strong, uint8_imgs, gt_imgs)\n",
    "augmentedstrong_patches, augmentedstronggt_patches = extract_patches(augmented_imgsstrong, augmented_gt)\n",
    "ystrong = to_categorical(augmentedstronggt_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.Sequential()\n",
    "\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu', padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model1.add(layers.MaxPooling2D((2,2)))\n",
    "model1.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(256, activation='relu'))\n",
    "model1.add(layers.Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1B - sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1B = models.Sequential()\n",
    "\n",
    "model1B.add(layers.Conv2D(64, (3, 3), activation='relu', padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model1B.add(layers.MaxPooling2D((2,2)))\n",
    "model1B.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model1B.add(layers.MaxPooling2D((2, 2)))\n",
    "model1B.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
    "model1B.add(layers.Flatten())\n",
    "model1B.add(layers.Dense(256, activation='relu'))\n",
    "model1B.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1C - softmax + categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1C = models.Sequential()\n",
    "\n",
    "model1C.add(layers.Conv2D(64, (3, 3), activation='relu', padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model1C.add(layers.MaxPooling2D((2,2)))\n",
    "model1C.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model1C.add(layers.MaxPooling2D((2, 2)))\n",
    "model1C.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
    "model1C.add(layers.Flatten())\n",
    "model1C.add(layers.Dense(256, activation='relu'))\n",
    "model1C.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1C.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - leaky relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2A = models.Sequential()\n",
    "\n",
    "model2A.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model2A.add(layers.MaxPooling2D((3,3)))\n",
    "model2A.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2A.add(layers.MaxPooling2D((3, 3)))\n",
    "model2A.add(layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2A.add(layers.Flatten())\n",
    "model2A.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2B = models.Sequential()\n",
    "\n",
    "model2B.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model2B.add(layers.MaxPooling2D((2,2)))\n",
    "model2B.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2B.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2B.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2B.add(layers.MaxPooling2D((2, 2)))\n",
    "model2B.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2B.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2B.add(layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same'))\n",
    "\n",
    "model2B.add(layers.Flatten())\n",
    "model2B.add(layers.Dense(2))\n",
    "model2B.add(layers.Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2BB = models.Sequential()\n",
    "\n",
    "model2BB.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding ='same' ,input_shape=(16, 16, 3)))\n",
    "model2BB.add(layers.MaxPooling2D((2,2)))\n",
    "model2BB.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2BB.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2BB.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2BB.add(layers.MaxPooling2D((2, 2)))\n",
    "model2BB.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "model2BB.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2BB.add(layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same'))\n",
    "\n",
    "model2BB.add(layers.Flatten())\n",
    "model2BB.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2BB.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - mirror padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "\n",
    "class SymmetricPadding2D(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, padding=[1,1], \n",
    "                 data_format=\"channels_last\", **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.data_format = data_format\n",
    "        self.padding = padding\n",
    "        super(SymmetricPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SymmetricPadding2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.data_format is \"channels_last\":\n",
    "            #(batch, depth, rows, cols, channels)\n",
    "            pad = [[0,0]] + [[i,i] for i in self.padding] + [[0,0]]\n",
    "        elif self.data_format is \"channels_first\":\n",
    "            #(batch, channels, depth, rows, cols)\n",
    "            pad = [[0, 0], [0, 0]] + [[i,i] for i in self.padding]\n",
    "\n",
    "        if K.backend() == \"tensorflow\":\n",
    "            import tensorflow as tf\n",
    "            paddings = tf.constant(pad)\n",
    "            out = tf.pad(inputs, paddings, \"REFLECT\")\n",
    "        else:\n",
    "            raise Exception(\"Backend \" + K.backend() + \"not implemented\")\n",
    "        return out \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "pad1 = [[2,2], [2,2], [2,2], [2,2]]\n",
    "Model3_input = keras.Input(shape=(16, 16, 3))\n",
    "x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(Model3_input)\n",
    "x = layers.Conv2D(64,(3,3), activation = lrelu, padding = 'same')(x)\n",
    "x = layers.MaxPooling2D((3,3))(x)\n",
    "x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "x = layers.MaxPooling2D((3, 3))(x)\n",
    "x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=lrelu)(x)\n",
    "Model3_output = layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "model3 = keras.Model(inputs=Model3_input, outputs=Model3_output, name='Model 3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatch(X, Y, batch_size):\n",
    "    \"\"\"\n",
    "    Procedure for real-time minibatch creation and image augmentation.\n",
    "     This runs in a parallel thread while the model is being trained.\n",
    "    \"\"\"\n",
    "    Y = tf.keras.utils.to_categorical(Y, 2)\n",
    "    while 1:\n",
    "        # Generate one minibatch\n",
    "        X_batch = np.empty((batch_size, 16,16, 3))\n",
    "        Y_batch = np.empty((batch_size, 2))\n",
    "        for i in range(batch_size):\n",
    "            # Select a random image\n",
    "            idx = np.random.choice(X.shape[0])\n",
    "            shape = X[idx].shape\n",
    "                    \n",
    "            # The label does not depend on the image rotation/flip (provided that the rotation is in steps of 90°)\n",
    "            X_batch[i] = X[idx]\n",
    "            Y_batch[i] = Y[idx]\n",
    "        yield (X_batch, Y_batch)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftmaxCategorical(): \n",
    "    pad1 = [[2,2], [2,2], [2,2], [2,2]]\n",
    "    model_input = keras.Input(shape=(16, 16, 3))\n",
    "    lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.1)\n",
    "    \n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(model_input)\n",
    "    x = layers.Conv2D(64,(5,5), activation = lrelu, padding = 'same')(model_input)\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #x = layers.Lambd#a(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.Conv2D(64,(3,3), activation = lrelu, padding = 'same')(x)\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x= layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "      \n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "    #x = layers.Lambda(lambda y: tf.pad(y, paddings = pad1, mode = 'REFLECT'))(x)\n",
    "    #x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation=lrelu)(x)\n",
    "    model_output = layers.Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=model_input, outputs=model_output, name='Model 4, SoftmaxCategorical')\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model 4, SoftmaxCategorical\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 1, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,214,786\n",
      "Trainable params: 1,214,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "977/977 [==============================] - 227s 233ms/step - loss: 0.5911\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e8cfcbdfc178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Hist = SoftB.fit(imgsall_patches,gtall_patches,  epochs=10, batch_size = 32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSoftC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_patches_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "batch_size = 64\n",
    "steps = math.ceil(img_patches.shape[0] / batch_size) \n",
    "DF = pd.DataFrame()\n",
    "\n",
    "SoftC = SoftmaxCategorical()\n",
    "SoftC.summary()\n",
    "SoftC.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3))\n",
    "Hist = SoftC.fit_generator(generate_minibatch(img_patches,gt_patches.reshape(-1), batch_size), epochs=1, steps_per_epoch= steps)\n",
    "#Hist = SoftB.fit(imgsall_patches,gtall_patches,  epochs=10, batch_size = 32)\n",
    "\n",
    "DF.append(Hist.history['val_accuracy'])\n",
    "        \n",
    "predictions = SoftC.predict(img_patches_test)\n",
    "predictions = np.squeeze(helper.binarize_predictions(predictions))\n",
    "predictions = predictions[:,1]\n",
    "sub.create_pred_images(predictions)\n",
    "submission_filename = 'model4_SoftB_all.csv'\n",
    "sub.create_submission(submission_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - original data - augmented data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax + binary crossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATA \n",
    "model1.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M1O = model1.fit(img_patches, gt_patches, batch_size = 32, epochs = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHT AUGMENTATION\n",
    "model1.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M1L = model1.fit(augmentedlight_patches, augmentedlightgt_patches, batch_size = 32, epochs = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(M1O.history['val_f1_m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEDIUM AUGMENTATIONS\n",
    "M1M = model1.fit(augmentedmedium_patches, augmentedmediumgt_patches, batch_size = 32, epochs = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STRONG AUGMENTATION\n",
    "M1S = model1.fit(augmentedstrong_patches, augmentedstronggt_patches, batch_size = 32, epochs = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + binary crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATA \n",
    "model1B.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M1BO = model1B.fit(img_patches, gt_patches, batch_size = 32, epochs = 5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHT AUGMENTATION \n",
    "M1BL = model1B.fit(augmentedlight_patches, augmentedlightgt_patches, batch_size = 32, epochs = 5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1BM = model1B.fit(augmentedmedium_patches, augmentedmediumgt_patches, batch_size = 32, epochs = 5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1BS = model1B.fit(augmentedstrong_patches, augmentedstronggt_patches, batch_size = 32, epochs = 5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax + categorical crossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATA \n",
    "model1C.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "M1CO = model1C.fit(img_patches, y, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHT AUGMENTATION\n",
    "model1C.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "M1LC = model1C.fit(augmentedlight_patches, ylight, batch_size = 32, epochs = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING MODEL 1 A-B-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame(columns = ['Model', 'Data','F1 score', 'Epochs'])\n",
    "\n",
    "Results['F1 score'] = M1O.history['val_f1_m']\n",
    "Results['Model'] = 1 \n",
    "Results['Data'] = 'Original'\n",
    "Results['Epochs'] = np.arange(1,len(M1O.history['val_f1_m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - leaky relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A : softmax + binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data \n",
    "model2A.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M2AO = model2A.fit(img_patches, gt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented light\n",
    "M2AL = model2A.fit(augmentedlight_patches, augmentedlightgt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented medium \n",
    "M2AM = model2A.fit(augmentedmedium_patches, augmentedmediumgt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2AS = model2A.fit(augmentedstrong_patches, augmentedstronggt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AA: A with softmax + categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2A.compile(loss = 'categorical_crossentropy',  optimizer = 'adam', metrics = ['accuracy'])\n",
    "M2AAO = model2A.fit(img_patches, y, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: softmax + binary (Cindy model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2B.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M2BO = model2B.fit(img_patches, gt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2BL = model2B.fit(augmentedlight_patches, augmentedlightgt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2BM = model2B.fit(augmentedmedium_patches, augmentedmediumgt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2BS = model2B.fit(augmentedstrong_patches, augmentedstronggt_patches, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid + categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2BB.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3), metrics = ['accuracy'])\n",
    "M2BBO = model2BB.fit(img_patches, y, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2BBL = model2BB.fit(augmentedlight_patches, ylight, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import keras\n",
    "batch_size = 64\n",
    "steps_per_epoch = math.ceil(img_patches.shape[0] / batch_size)\n",
    "\"\"\"def softmax_categorical_crossentropy(y_true, y_pred):\n",
    "       \n",
    "        Uses categorical cross-entropy from logits in order to improve numerical stability.\n",
    "        This is especially useful for TensorFlow (less useful for Theano).           \n",
    "        return K.categorical_crossentropy(y_pred, y_true, from_logits=True)\n",
    "    \"\"\"\n",
    "model2BB.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3), metrics = ['accuracy'])\n",
    "#model.fit(img_patches, gt_patches, batch_size = 32, epochs = 2, validation_split = 0.2)\n",
    "#F1 = 0.645\tsecondary = 0.805\n",
    "model2BB.fit_generator(generate_minibatch(img_patches,gt_patches, batch_size),\n",
    "                    epochs=10, steps_per_epoch= steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = imgs.copy()\n",
    "fullgt = gt_imgs.copy()\n",
    "\n",
    "for n in range(len(fullgt)):\n",
    "        augmented = helper.image_augmentation(image_size = 256)(image=full[n], mask=fullgt[n])\n",
    "        full.extend(augmented['image'])\n",
    "        fullgt.extend(augmented['mask'])\n",
    "        \n",
    "full_patches, fullgt_patches = extract_patches(full, fullgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2BB.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3), metrics = ['accuracy'])\n",
    "# F1 = 0.638\t0.800\n",
    "M2BBfullgen = model2BB.fit_generator(generate_minibatch(full_patches,fullgt_patches, batch_size),\n",
    "                    epochs=10, steps_per_epoch= steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = imgs.copy()\n",
    "completegt = gt_imgs.copy()\n",
    "\n",
    "for n in range(len(completegt)):\n",
    "        augmented = helper.pre_process()(image=complete[n], mask=completegt[n])\n",
    "        complete.extend(augmented['image'])\n",
    "        completegt.extend(augmented['mask'])\n",
    "        \n",
    "complete_patches, completegt_patches = extract_patches(complete, completegt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFIN = models.Sequential()\n",
    "\n",
    "modelFIN.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding ='same' ,input_shape=(16, 16, 3)))\n",
    "modelFIN.add(layers.MaxPooling2D((2,2)))\n",
    "modelFIN.add(layers.Conv2D(64, (3, 3), activation=lrelu, padding = 'same'))\n",
    "modelFIN.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "modelFIN.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "modelFIN.add(layers.MaxPooling2D((2, 2)))\n",
    "modelFIN.add(layers.Conv2D(128, (3, 3), activation=lrelu, padding = 'same'))\n",
    "modelFIN.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "modelFIN.add(layers.Conv2D(256, (3, 3), activation=lrelu, padding = 'same'))\n",
    "\n",
    "modelFIN.add(layers.Flatten())\n",
    "modelFIN.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_imgsfull = [None] * len(full)\n",
    "for i, image in enumerate(full): \n",
    "    uint8_imgfull = helper.img_float_to_uint8(image)\n",
    "    uint8_imgsfull[i] = uint8_imgfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgslightfull, augmented_gtfull = augment_imgs(light, uint8_imgsfull, fullgt)\n",
    "augmentedlight_patchesfull, augmentedlightgt_patchesfull = extract_patches(augmented_imgslightfull, augmented_gtfull)\n",
    "ylightfull = to_categorical(augmentedlightgt_patchesfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFIN.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3), metrics = ['accuracy'])\n",
    "M2BBfullgenL = modelFIN.fit_generator(generate_minibatch(augmentedlight_patchesfull, augmentedlightgt_patchesfull, batch_size),\n",
    "                    epochs=10, steps_per_epoch= steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albu.augmentations.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2BB.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 1e-3), metrics = ['accuracy'])\n",
    "M2BBLgen = model2BB.fit_generator(generate_minibatch(augmentedlight_patches,augmentedlightgt_patches, batch_size),\n",
    "                    epochs=8, steps_per_epoch= steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2BBMgen = model2BB.fit_generator(generate_minibatch(augmentedmedium_patches,augmentedmediumgt_patches, batch_size),\n",
    "                    epochs=8, steps_per_epoch= steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - original data - augmented data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M3O = model3.fit_generator(img_patches, gt_patches, batch_size = 15, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss = 'binary_crossentropy',  optimizer = 'adam', metrics = ['accuracy', f1_m])\n",
    "M3L = model3.fit(augmentedlight_patches, augmentedlightgt_pathes, batch_size = 32, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(helper.binarize_predictions(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction as an image\n",
    "img_idx = 49\n",
    "img_indexed = imgs[img_idx]\n",
    "img_pat = helper.img_crop(img_indexed, patch_size, patch_size)\n",
    "img_pat = np.asarray(img_pat)\n",
    "prediction = model.predict(img_pat)\n",
    "\n",
    "prediction = prediction[:,1]\n",
    "\n",
    "w = gt_imgs[img_idx].shape[0]\n",
    "h = gt_imgs[img_idx].shape[1]\n",
    "\n",
    "prediction = helper.binarize_predictions(prediction)\n",
    "prediction = single_patch_cleaner(prediction.reshape((w//patch_size, h//patch_size))).flatten()\n",
    "\n",
    "predicted_im = helper.label_to_img(w, h, patch_size, patch_size, prediction)\n",
    "\n",
    "cimg = helper.concatenate_images(imgs[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = helper.make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import submission as sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "patch_size = 16\n",
    "\n",
    "img_test = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'Datasets/test_set_images/test_' + str(i) + '/test_' + str(i) + '.png' \n",
    "    img_test.append(helper.load_image(image_filename))\n",
    "\n",
    "img_patches_test = [helper.img_crop(img_test[i], patch_size, patch_size) for i in range(n)]\n",
    "img_patches_test = np.asarray([img_patches_test[i][j] for i in range(len(img_patches_test)) for j in range(len(img_patches_test[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model2BB.predict(img_patches_test)\n",
    "predictions = np.squeeze(helper.binarize_predictions(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub.create_pred_images(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_filename = 'submission2BBfullgen.csv'\n",
    "   \n",
    "sub.create_submission(submission_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction as an image\n",
    "img_idx = 49\n",
    "img_indexed = img_test[img_idx]\n",
    "img_pat = helper.img_crop(img_indexed, patch_size, patch_size)\n",
    "img_pat = np.asarray(img_pat)\n",
    "prediction = model.predict(img_pat)\n",
    "\n",
    "prediction = prediction[:,1]\n",
    "\n",
    "w = img_test[img_idx].shape[0]\n",
    "h = img_test[img_idx].shape[1]\n",
    "\n",
    "prediction = helper.binarize_predictions(prediction)\n",
    "prediction = single_patch_cleaner(prediction.reshape((w//patch_size, h//patch_size)))\n",
    "\n",
    "predicted_im = helper.label_to_img(w, h, patch_size, patch_size, prediction.flatten())\n",
    "cimg = helper.concatenate_images(img_test[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = helper.make_img_overlay(img_test[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
